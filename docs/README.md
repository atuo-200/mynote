## 写在前面的絮絮叨叨

该课程笔记是根据吴恩达教授的机器学习课程整理的[[中英字幕]吴恩达机器学习系列课程](https://www.bilibili.com/video/av50747658?p=1)，感谢吴恩达教授。

## 机器学习的概念

#### 使用到机器学习的一些案例

```
数据挖掘
    网页点击流数据分析

人工无法处理的工作(量大)
    手写识别
    计算机视觉

个人定制
    推荐系统

研究大脑

……
```

### 什么是机器学习

这里主要有两种定义：

+ Arthur Samuel (1959). Machine Learning:  Field of study that gives computers the ability to learn without being  explicitly programmed.

在没有明确设置的情况下，使计算机具有学习能力的研究领域

+ Tom Mitchell (1998) Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some **task T** and some **performance measure P**, if its performance on T, as measured by P, improves with **experience E**. 

计算机程序从经验E中学习，解决某一任务T，进行某一性能度量P，测定P在T上的表现因经验E而提高。

Tom Mitchell 的定义更为现代和正式。

### 机器学习算法

主要有两种机器学习算法(后面会阐述更多)：

+ 监督学习

+ 无监督学习

两者的区别为在于是否需要人工参与数据结果的标注

更多的机器学习算法：

+ 半监督学习: 介于监督学习于无监督学习之间

+ 推荐算法: 就是那些买完某商品后还推荐同款商品的购物网站所用的算法，剁手的万恶之源。

+ 强化学习: 类比小孩学步，每个动作都会对环境有所影响，而环境的反馈又可以引导该学习算法做出更好的反馈。

+ 迁移学习

### 监督学习

监督学习，即为教计算机如何去完成预测任务，预先给一定数据量的输入和对应的结果（即训练集），建立模型拟合数据，最后让计算机根据该模型预测给定输入数据所对应的结果。

监督学习一般用于解决两种问题：

1、回归问题(Regression)

回归问题即为预测一系列的<u>连续值</u>。比如预测房屋价格

2、分类问题(Classification)

分类问题即为预测多个<u>离散值</u>。即根据数据预测被预测对象属于哪个分类。比如垃圾邮件分类问题

当特征量很大的时候，<u>支持向量机</u>这个算法能让计算机处理大量特征。

### 无监督学习

无监督学习，训练集不会有人为标注的结果（无反馈），我们不会给出结果或无法得知训练集的结果是什么样，而是单纯由计算机通过无监督学习算法自行分析，从而得出结果。

无监督学习一般分为两种。

1、聚类(Clustering)（计算机把特定的数据集归为几个不同的簇，故叫做聚类算法）

+ 新闻聚合

+ DNA 个体聚类

+ 天文数据分析

+ 市场细分

+ 社交网络分析

2、非聚类(Non-clustering)

+ 鸡尾酒问题

在机器学习刚开始时，在做原型搭建的时候也应该先考虑使用类似于 Octave 这种便于计算的编程软件，当其已经可以工作后，才将模型移植到其他的高级编程语言中。

Octave 与 MATLAB 语法相近，MATLAB 为商业软件，Octave开源且免费。



## 一元线性回归

### 单变量线性回归模型

![image-20200303154929409](.\image\image-20200303154929409.png)

参数θ的变化才决定了输出结果，所以怎样解得θ以更好地拟合数据，成了求解该问题的最终问题。

### 代价函数

有些地方，损失函数和代价函数的概念混在一起使用，吴恩达老师在其公开课上对这两者做了区分。

损失函数(Loss/Error Function): 计算单个样本的误差。

代价函数(Cost Function): 计算整个训练集所有损失函数之和的平均值。

为了度量建模误差，我们引入代价函数的概念，即应用统计学中的均方误差函数（最小二乘法）：

![image-20200303164316589](.\image\image-20200303164316589.png)

系数½存在与否都不会影响结果，这里是为了在应用梯度下降时便于求解，平方的导数会抵消掉½。

### 单变量线性回归模型的代价函数

![image-20200303171040641](.\image\image-20200303171040641.png)

### 双变量线性回归模型的代价函数（这里涉及到了多变量成像）

![image-20200303171933543](.\image\image-20200303171933543.png)

一元函数的成像是一条线，二元函数的成像是一个面，三元函数的成像类似于一个球体，再多元函数的成像就无法绘图表示。上面的3D图即为双变量线性回归模型的代价函数成像，因为3D图不便标注，我们把上面的3D图转换为轮廓图（类似等高线，在同一条曲线上代表在同一高度上，即同一代价函数值）来观察。我们在训练模型的时候旨在使代价函数收敛到最小值，如上图的碗底，也如下图所标注。

![image-20200303171625089](.\image\image-20200303171625089.png)

### 梯度下降法

在特征量很大的情况下，即便是借用计算机来生成图像，人工的方法也很难读出代价函数的最小值，并且大多数情况无法进行可视化，故引入梯度下降(Gradient Descent)方法，让计算机自动找出最小化代价函数时参数对应的值。

梯度下降背后的思想是：开始时，我们随机选择一个参数组合即起始点，计算代价函数，然后寻找下一个能使得代价函数下降最多的参数组合。不断迭代，直到找到一个<u>局部最小值(local minimum)</u>，由于下降的情况只考虑当前参数组合周围的情况，所以无法确定当前的局部最小值是否就是<u>全局最小值(global minimum)</u>，不同的初始参数组合，可能会产生不同的局部最小值。如下图的“下山”过程。

![image-20200303182831492](.\image\image-20200303182831492.png)

梯度下降法的公式

![image-20200303182238111](.\image\image-20200303182238111.png)

其中

![image-20200303182309739](.\image\image-20200303182309739.png)

公式中，学习速率决定了参数值变化的速率即**下山迈多大步子**，而偏导这部分决定了下降的方向即**下一步往哪里**走（当然实际上的走多少距离是由偏导值给出的）。

注意，在计算时要批量更新参数值，而不是单个更新参数值。

最后，梯度下降不止可以用于线性回归中的代价函数，还通用于最小化其他的代价函数。

### 学习率

对于学习速率α，需要选取一个合适的值才能使得梯度下降算法运行良好

+ 学习速率过小的时候，收敛得太慢，需要多次的迭代

+ 学习速率过大的时候，可能越过最低点，甚至导致无法收敛

学习速率只需选定即可，不需要在运行梯度下降算法的时候进行动态改变，随着斜率越来越接近于0，代价函数的变化幅度会越来越小。

### 一元线性回归中的梯度下降

由于一元线性回归函数呈现碗状，且只有一个全局的最优值，所以函数一定总会收敛到全局最小值（学习速率不可过大）。同时，函数J被称为凸二次函数，而线性回归函数求解最小值问题属于凸函数优化问题。

有些时候我们并不需要使用像梯度下降的迭代算法，我们可以使用正规方程组方法来一次性求解出代价函数的最小值。但 该方法与梯度下降法相比，梯度下降法适用于更大的数据集。我们会在后面介绍正规方程组方法，在此之前，我们先回顾下线性代数的基础知识。

## 线性代数基础知识

### 回顾线性代数的基础知识

矩阵是指由数字组成的矩形阵列，并写在方括号内。

矩阵的维度为矩阵的行数乘以列数。

向量是一个特殊的矩阵，向量是一个只有一列的矩阵。

矩阵的加法指的是这两个矩阵的每一个元素都逐个相加。

标量与矩阵相乘指的是标量和矩阵的每一个元素都相乘得到一个新的矩阵

矩阵与矩阵的乘法。

![image-20200304182120396](.\image\image-20200304182120396.png)

矩阵乘法的顺序不能颠倒：AB ！= BA，即不满足交换律，但满足结合律。

AI = IA = A，I为单位矩阵。

只有方阵才有逆矩阵。AA<sup>-1</sup> = A<sup>-1</sup>A = I。

不存在逆矩阵的矩阵，它的专有名词是奇异矩阵或者叫退化矩阵。

零矩阵是奇异矩阵。

矩阵的转置：把行转成列。

## 多元线性回归

### 多元线性回归的梯度下降法

多变量假设函数h表示为


$$
h_\theta(x) = \theta_0 + \theta_1x_1 + \cdots + \theta_nx_n
$$


参数向量的维度为n + 1，在特征向量中添加 x0 = 1 后，其维度也变为n + 1，则运用线性代数，可简化h
$
h_\theta(X) = \left[
 \begin{matrix}
   \theta_1 & \theta_2 & \cdots & \theta_n \\
  \end{matrix}
  \right]
  \left[
 \begin{matrix}
   x_1 \\ x_2 \\ \cdots \\ x_n \\
  \end{matrix}
  \right] = \theta^Tx
$


多变量代价函数类似于单变量代价函数，即
$$
J(\theta_0,\theta_1\cdots\theta_n) = \frac{1}{2m}\sum_{i=1}^{m}{(h_\theta(x^i) - y^i).x^i_j}
$$


则多变量梯度下降公式为
$$
\theta_j := \theta_j - \alpha\frac{\varphi}{\varphi\theta_j}J(\theta_0,\theta_1\cdots\theta_n)
$$


解出偏导得
$$
\theta_j := \theta_j - \alpha\frac{1}{m}\sum_{i=1}^{m}{(h_\theta(x^i) - y^i).x^i_j}
$$


当然，同单变量梯度下降一样，计算时需要同时更新所有参数。

又因为
$$
h_\theta(x) = \theta^Tx
$$


则得到同时更新参数的向量化实现
$$
\theta = \theta - \alpha\frac{1}{m}(X^T(X\theta - y))
$$


X：训练集数据，m * （n + 1）维矩阵（包含基本特性）

### 多元线性回归的梯度下降法之特征缩放

由于各特征值的范围不一，可能会影响代价函数收敛速度。特征缩放即是保证多个特征的取值在相近的范围内，这样梯度下降法能更快地收敛。

当我们进行特征缩放时，我们的目的是把特征的取值约束到-1到+1的范围内。而对于特征的范围，并不一定需要使得-1 <= x <= 1，类似于1 <= x <= 3等也是可取的，而诸如-100 <= x <= 100，-0.00001 <= x <= 0.00001，就显得过大/过小了。

除了人工选择特征并除以或乘以一个数的方式进行特征缩放，均值归一化(Mean normalization)方法更为便捷。

### 如何选择合适的学习率

通常，有两种方法来确定代价函数是否收敛

+ 多次迭代收敛法

  + 无法确定需要多少次迭代
  + 较易绘制关于迭代次数的图像

  + 根据图像易预测所需的迭代次数

+ 自动化测试收敛法（比较阈值）
  + 不易选取阈值
  + 代价函数近乎直线时无法确定收敛情况

而对于自动化测试收敛法，很难选取一个合适的阈值，所以我们一般确定一个代价函数是否收敛是采取多次迭代收敛法来绘图观察代价函数随着迭代次数的收敛情况，从而选择一个合适的学习率，当学习率过大时，代价函数会无法收敛，出现上下波动或逐渐增大的情况，当学习率过小时，会收敛得过慢。

通过不断改变学习率的值，绘制并观察图像，并以此确定合适的学习速率。 尝试时可取学习率值如：
$$
\cdots,0.001,0.003,0.01,0.03,0.1,\cdots    (每隔3倍取一个值)
$$


### 多项式回归

线性回归只能以直线来对数据进行拟合，有时候需要使用曲线来对数据进行拟合，即多项式回归(Polynomial Regression)。
$$
假设只有一个特征
$$

$$
一个二次方模型：h_\theta(x) = \theta_0 + \theta_1x + \theta_2x^2
$$

$$
一个三次方模型：h_\theta(x) = \theta_0 + \theta_1x + \theta_2x^2 + \theta_3x^3
$$

$$
x_i := \frac{x_i - average(x)}{maximum(x) - minimun(x)},使得x_i ∈ (-1,1)
$$

$$
一个平方根模型：h_\theta(x) = \theta_0 + \theta_1x + \theta_2x^2 + \theta_2\sqrt{x}
$$



在使用多项式回归时，要记住非常有必要进行特征缩放。

### 正规方程法

对于一些线性回归问题来说，正规方程法给出了一个更好的解决问题的方式。

正规方程法，即令代价函数的导数置于0，通过解析函数的方式求出参数向量的值：
$$
\theta = (X^TX)^-1X^Ty
$$

$$
X^T：矩阵的转置
$$

$$
X^-1：矩阵的逆矩阵
$$



正规方程法和梯度下降法的对比

| 条件               | 正规方程法             | 梯度下降法 |
| ------------------ | ---------------------- | ---------- |
| 是否需要选取学习率 | 不需要                 | 需要       |
| 是否需要迭代计算   | 不需要                 | 需要       |
| 特征量大时         | 不适用，一万特征以内   | 适用       |
| 适用范围           | 线性模型，且矩阵皆可逆 | 各类模型   |

### 正规方程法之矩阵不可逆怎么办

正规方程法无法应用于不可逆的矩阵，而发生矩阵不可逆通常由于

+ 特征之间线性相关，比如同时包含英寸的尺寸和米为单位的尺寸两个特征，它们是线性相关的。

+ 特征数量大于训练集的数量（m < n）。

如果发现X^TX的结果不可逆，可尝试

+ 减少多余/重复特征。

+ 增加训练集数量。

+ 使用正则化（后面介绍）。

对于这类不可逆的矩阵，我们称之为奇异矩阵或退化矩阵。

这种情况下，如果还想使用正规方程法，在Octave中，可以选用 `pinv` 函数，`pinv` 区别于 `inv`，`pinv` 函数被称为伪逆函数，在矩阵不可逆的时候，使用这个函数仍可正确地计算出参数向量θ的值。

后面会介绍到用正则化方法解决正规方程法中的矩阵不可逆问题。

## Octave的使用

## Octave的使用

吴恩达教授的机器学习视频中5.1到5.6是关于Octave的简单入门，需要更详细的Octave教程内容，可以查询

[GNU Octave](https://octave.org/doc/v4.2.2/)

## 逻辑回归

### 分类

在分类问题中，预测的结果是离散值（结果是否属于某一类），逻辑回归算法(Logistic Regression)被用于解决这类分类问题。

把线性回归算法应用于分类问题，并不是个好主意。

### 逻辑回归算法的假设函数表达式

为了使hθ ∈ (0,1)，引入逻辑回归模型，定义假设函数
$$
h_θ(x) = g(z) = g(θ^Tx)
$$

$$
应用sigmoid函数：g(z) = \frac{1}{1+e^-z}
$$

两者结合，得逻辑回归算法的假设函数表达式
$$
h_θ(x) = g(θ^Tx) = \frac{1}{1+e^-θ^Tx}
$$


逻辑回归模型中hθ的作用是，根据输入x以及参数θ，计算出“y = 1”的可能性，概率学中表示为

![image-20200307133327743](.\image\image-20200307133327743.png)

### 决策边界

简单点来说，决策边界（Decision Boundary）就是分类的分界线。

在上面讲到逻辑回归算法的假设函数表达式的时候，我们得到假设函数的输出为“y = 1”的概率。要把得出的概率映射到分类结果，我们在假设函数上设定一个阈值0.5。
$$
h_θ(x) = g(θ^Tx) = \frac{1}{1+e^-θ^Tx}
$$

$$
h_θ(x) < 0.5 \rightarrow y = 0
$$



再来看看sigmoid函数的图像

![image-20200307135336255](.\image\image-20200307135336255.png)
$$
观察可得，g(z) \geq 0.5，有z \geq 0，综合上面，我们可以把阈值0设定在自变量z上，通过z大小得出分类结果
$$

$$
当z \rightarrow  +\infty 推出y = 1
$$

$$
当z \rightarrow  -\infty 推出y = 0来看个例子更为直观
$$

$$
我们设h_θ(x) = g(θ_0+θ_1x_1+θ_2x_2)是下图模型的假设函数
$$




![image-20200307142904885](.\image\image-20200307142904885.png)
$$
那么我们只要使θ_0 + θ_1x_1 + θ_2x_2 \geq 0时，就可以预测y = 1
$$

$$
当取θ = \begin{bmatrix}
-3\\ 
1\\ 
1\\
\end{bmatrix}，我们可以绘制出图中那条品红色的线为决策边界，即
$$

$$
当-3 + x_1 + x_2 \geq 0，我们预测y = 1;当-3 + x_1 + x_2 < 0，我们预测y = 0
$$
上面讨论了逻辑回归模型中线性拟合的例子，下面则是一个多项式拟合的例子
$$
h_θ(x) = g(θ_0 + θ_1x_1 + θ_3x_1^2 + θ_4x_2^2)
$$

$$
取θ = \begin{bmatrix}
-1\\ 
0\\ 
0\\
1\\
1\\
\end{bmatrix}
$$

$$
这样我们可以在原点处得到一个单位圆作为决策边界（x_1^2 + x_2^2 = 1）
$$



![image-20200307150138320](.\image\image-20200307150138320.png)

当然，通过一些更为复杂的多项式，能拟合出更为复杂的决策边界，决策边界由参数向量θ决定。

## 逻辑回归算法的代价函数

逻辑回归的代价函数长什么样，提到这个问题前我们先回忆一下线性回归的代价函数
$$
J(\theta) = \frac{1}{2m}\sum_{i=1}^{m}{(h_\theta(x^i)-y^i)}^2
$$
但逻辑回归算法中
$$
h_\theta(x) = g(\theta^Tx)
$$


把hθ代入J(θ)中，我们绘制一元情况下的J(θ)函数，得出一个非凸函数

![image-20200310122936179](.\image\image-20200310122936179.png)

由图所示，图中有很多局部最小值，这使得我们用梯度下降法很难收敛到全局最小值。由此可见，逻辑回归算法中再使用均方误差函数（MSE）作为代价函数就显得不适用了，我们使用另一种代价函数
$$
J(\theta) = \frac{1}{m}\sum_{i=1}^{m}{Cost(h_\theta(x^i),y^i)}
$$
![image-20200310124443775](.\image\image-20200310124443775.png)

其中J(θ)的图像如下

![image-20200310124558436](.\image\image-20200310124558436.png)

由图可知，当训练集的结果为y = 1时，随着假设函数趋向于1，代价函数的值会趋于0，即意味着拟合程度很好。如果假设函数此时趋于0，代价函数则会给出一个很高的惩罚

我们把上面的代价函数合成一个式子表示

![image-20200310124527800](.\image\image-20200310124527800.png)

### 高级优化

我们编写代码给出代价函数及其偏导数然后传入梯度下降算法中，接下来算法则会为我们最小化代价函数给出参数的最优解。这类算法被称为<u>最优化算法(Optimization Algorithms)</u>。

一些最优化算法：

+ 梯度下降法(Gradient Descent)

+ 共轭梯度算法(Conjugate gradient)

+ 牛顿法和拟牛顿法(Newton's method & Quasi-Newton Methods)

  + DFP算法

  + 局部优化法(BFGS)

  + 有限内存局部优化法(L-BFGS)

+ 拉格朗日乘数法(Lagrange multiplier)

对比梯度下降法，一些最优化算法会更为复杂，难以调试，自行实现又困难重重，开源库效率也不一（这告诉我们要使用这些算法时，做个调包侠），但这些算法通常效率更高，更适合用于更大的机器学习问题，并通常无需手动选择学习速率（这就省去了很多烦恼）。 

Octave/Matlab 中对这类高级算法做了封装，易于调用。我们只需在使用的时候懂得去用它们，而不需去理解这些算法的具体细节，因为这些算法都过于复杂，不要以卵击石。

### 用逻辑回归算法解决多类别分类问题

这里讨论下多类别分类问题。

如何用逻辑回归算法解决多类别分类问题，<u>原理</u>是把多类别分类问题转化为多个二元分类问题，拟合出多个二元分类器（“多个”的数目取决于预测结果有多少个类别），然后把单个样本输入到多个二元分类器中，逐个计算出样本属于哪个类别的概率。

![image-20200310134621033](.\image\image-20200310134621033.png)
$$
分类器定义：h_θ^i(x) = P(y = i|x;θ)，i = (1,2...k)
$$


> 其中，分类器输出y = i（属于第i个类别的可能性），其输出结果不再是一个实数，而是一个向量，如果类别总数为k，现在k就是一个k维向量。
>
> k：类别总数，如上图k = 3

对于某个样本实例，需计算所有的k种分类情况得到 ，然后看分为哪个类别时预测输出的值最大，就说它输出属于哪个类别，即
$$
y = max(h_θ^i(x))
$$


## 正则化

### 过拟合问题

谈到过拟合问题前或许可以去了解一下机器学习中的偏差和方差，一个视频：https://www.imooc.com/video/17609

欠拟合的情况：偏差大、方差小

+ 由于训练不足，学习器的拟合能力不够强，偏差比较大

+ 也是由于拟合能力不强，数据集的扰动也无法使学习器产生显著变化

过拟合的情况：偏差小、方差大

+ 充分训练后，学习器的拟合能力已非常强，导致训练数据的非全局的特征都被学习到，而造成数据的轻微扰动都会导致学习器发生显著变化

+ J(θ)趋近于0，过度拟合，模型泛化到新数据集的能力弱

如何避免过拟合问题：

1、减少特征的数量（减少特征的方式易丢失有用的特征信息）

+ 手动选取需保留的特征

+ 使用模型选择算法来选取合适的特征(如 PCA 算法)

2、正则化(Regularization)（当有很多参数对于模型只有轻微影响时，正则化方法的表现很好）

+ 可保留所有参数（许多有用的特征都能轻微影响结果）

+ 减少/惩罚各参数所占比重大小(magnitude)，以减轻各参数对模型的影响程度

### 正则化之在代价函数中添加惩罚项

很多时候由于特征数量过多，过拟合时我们很难选出要保留的特征，应用正则化方法则是很好的选择。

一个复杂的多阶式较易过拟合，比如
$$
θ_0 + θ_1x + θ_2x^2 + θ_3x^3 + θ_4x^4
$$


为了保留各个参数的信息（这是使用正则化的目的），不修改假设函数，改而修改代价函数
$$
J(\theta) = \frac{1}{2m}\sum_{i=1}^{m}{(h_\theta(x^i)-y^i)}^2 + 1000\theta_3^2 + 1000\theta_4^2
$$


上式中，在代价函数中增加了θ3、θ4 的惩罚项(penalty term) ，如果要最小化代价函数，那么势必需要极大地减小 θ3、θ4，从而使得假设函数中的θ3、θ4这两项的参数非常小，相当于没有了，假设函数也就<u>变得简单</u>了，从而在保留各参数的情况下避免了过拟合问题。

![image-20200310154911904](.\image\image-20200310154911904.png)

有时也无法决定要减少哪个参数，故统一惩罚除了θ0外的所有参数。
$$
J(\theta) = \frac{1}{2m}[\sum_{i=1}^{m}{(h_\theta(x^i)-y^i)}^2 + \lambda\sum_{j=1}^{n}θ^2_j]
$$
其中

![image-20200310155418245](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200310155418245.png)

λ正则化参数类似于学习速率，需要我们自行对其选择一个合适的值。

+ 过大：会导致导致模型欠拟合(假设函数可能会近乎变成一条直线 )

+ 过小：无法解决过拟合问题（等于没有）

正则化符合奥卡姆剃刀(Occam's razor)原理。在所有可能选择的模型中，能够很好地解释已知数据并且十分简单才是最好的模型，也就是应该选择的模型。

### 线性回归中的正则化

上文介绍了在代价函数中添加正则化项，，这里我们介绍把正则化应用到线性回归的梯度下降法中（我感jio是把正则化过的代价函数代入到梯度下降法中）。

![image-20200311191127831](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200311191127831.png)

应用了正则化的正规方程法

![image-20200311191309991](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200311191309991.png)

λ.L：正则化项

L：第一行第一列为0的n + 1维单位矩阵

正则化可以解决正规方程法中不可逆的问题，即增加了λ.L正则化项后，可以保证X^TX + λ.L可逆，即使X^TX不可逆。

### 逻辑回归中的正则化

应用了正则化的逻辑回归算法

![image-20200311192929535](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200311192929535.png)

## 神经网络

### 进入神经网络的大门

前面我们介绍了逻辑回归算法在分类中的应用，但在实际处理时，特征量通常会很多，如果再构造高阶多项式等，特征数量将会急剧增加，这使得回归模型的复杂度太高，可见并不合适。神经网络无需构造高阶多项式，在特征量很大时也可以处理的很好。

感受一下计算机视觉中的特征之多

![image-20200311194128114](.\image\image-20200311194128114.png)

人们推论假设人的大脑完成这么多事情背后的学习算法只有一种，那么如果能找出这种学习算法并应用于计算机中，那梦想中和人一样的人工智能就成真了，神经网络就是致力于模仿这一种算法。

### 模型表示

先来看看单个数学神经元结构

![image-20200314111138681](.\image\image-20200314111138681.png)

单个神经元结构组合成为神经网络，用以完成更复杂的功能

![image-20200311205153866](.\image\image-20200311205153866.png)

其中：

> x0: 偏置单元(bias unit)，x0 = 1.
>
> θ: 权重(weight)，即参数。
>
> 激活函数: 即逻辑函数等。
>
> 输入层: 对应于训练集中的特征。
>
> 输出层: 对应于训练集中的结果。

对输入层(Layer 1)的所有激活单元应用激活函数，从而得到隐藏层(Layer 2)中激活单元的值

![image-20200311211028022](.\image\image-20200311211028022.png)

对 Layer 2 中的所有激活单元应用激活函数，从而得到输出

![image-20200311211056613](.\image\image-20200311211056613.png)

上面的计算过程被称为<u>前向传播(Forward propagation)</u>，即从输入层开始，一层一层地向下计算并传递结果。

前向传播过程也可向量化实现，由上面的神经网络推出的向量化实现

![image-20200311213626591](.\image\image-20200311213626591.png)
$$
α^2 = g(θ^1α^1)
$$

$$
h_θ(x) = a^3 = g(θ^2α^2)
$$

上面只是一个简单的神经网络模型，神经网络可有多层，每层的激活单元数量也并不固定。我们习惯将输入层称为神经网络的第0层，如上图的神经网络被称为二层网络。

### 神经网络的多类别分类

神经网络，要实现多类别分类，其实只要修改一下输出层，让输出层包含多个输出单元即可。这时神经网络中的预测结果是K维向量，而不再只是一个实数了。

![image-20200316171732228](.\image\image-20200316171732228.png)

### 神经网络中的代价函数

![image-20200316172653623](.\image\image-20200316172653623.png)

![image-20200316172819126](.\image\image-20200316172819126.png)

乍看有点复杂，我们回顾下逻辑回归算法的代价函数而尝试去理解以上公式

![image-20200316172953121](.\image\image-20200316172953121.png)

+ 神经网络中的代价函数左边的变化实际上是为了求解K分类问题，即公式会对每个样本特征都运行K次，并依次给出分为第K类的概率。

+ 神经网络中的代价函数右边的正则化项比较容易理解，每一层有多维矩阵![image-20200316173225199](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200316173225199.png)从左到右看这个三次求和式 ![image-20200316173258178](.\image\image-20200316173258178.png) 就是对每一层间的多维矩阵权重  依次平方后求取其除了偏置权重部分的和值，并循环累加即得结果。

### 反向传播算法

反向传播算法很难可视化表示出来，它犹如一个黑盒。

我们可以尝试类比用前向传播算法来理解反向传播算法。

[“反向传播算法”过程及公式推导（超直观好懂的Backpropagation）](https://blog.csdn.net/ft_sunshine/article/details/90221691)

反向传播算法，即从输出层开始不断向前迭代，根据上一层的误差依次计算当前层的误差，以求得代价函数的偏导。

### 参数展开

在 Octave/Matlab 中，如果要使用类似于一些高级最优化函数，其函数参数、函数返回值等都为且只为向量，而由于神经网络中的权重是多维矩阵，所以需要用到参数展开这个技巧。

说白了参数展开就是把一个多维矩阵展开成为一个长长的向量，便于传入函数，之后再根据矩阵维度，转回矩阵即可。

```octave
% 多个矩阵展开为一个向量
Theta1 = ones(11, 10);    % 创建维度为 11 * 10 的矩阵
Theta2 = ones(2, 4) * 2;  % 创建维度为 2 * 4 的矩阵
ThetaVec = [Theta1(:); Theta2(:)]; % 将上面两个矩阵展开为向量


% 从一个向量重构还原回多个矩阵
Theta1 = reshape(ThetaVec(1:110), 11, 10)
Theta2 = reshape(ThetaVec(111:118), 2, 4)
% Theta2 = reshape(ThetaVec(111:(111 + 2 * 4) - 1), 2, 4)
```



### 梯度检验

由于神经网络模型中的反向传播算法较为复杂，在小细节非常容易出错，从而无法得到最优解，故引入梯度检验。

梯度检验采用数值估算(Numerical estimation)梯度的方法，被用于验证反向传播算法的正确性。

![image-20200317121359458](.\image\image-20200317121359458.png)

即估算![image-20200317121427396](.\image\image-20200317121427396.png)

而对于矩阵θ，则有

![image-20200317122345291](.\image\image-20200317122345291.png)

在得出 gradApprox 梯度向量后，将其同之前计算的偏导比较，如果相等或很接近，即说明算法没有问题。

在确认反向传播算法没有问题后（一般只需运行一次），由于梯度检验计算量很大很耗时，所以一定要禁用它。

### 随机初始化

逻辑回归中，初始参数向量全为 0 没什么问题，在神经网络中，情况就不一样了。

在神经网络中，对参数初始化时，要使用随机初始化的思想。

### 综合

一般来说，应用神经网络有如下步骤：

1、神经网络的建模（后续补充）

+ 选取特征，确定特征向量x的维度，即输入单元的数量。

+ 鉴别分类的类别数目，确定预测向量的维度，即输出单元的数量

+ 确定隐藏层有几层以及每层隐藏层有多少个隐藏单元。

> 默认情况下，隐藏层至少要有一层，也可以有多层，层数越多一般意味着学习效果越好，计算量越大。

2、训练神经网络

+ 随机初始化初始权重矩阵

+ 用前向传播算法计算预测值

+ 计算代价函数的值

+ 应用反向传播算法计算代价函数的偏导数

+ 使用梯度检验检查算法的正确性，别忘了用完就禁用它

+ 丢给最优化函数最小化代价函数

> 由于神经网络的代价函数非凸，最优化时不一定会收敛在全局最小值处

## 机器学习诊断法

### 机器学习诊断法之数据集划分

接下来将用一系列的方法来对机器学习算法作一定的评估，以此选择一个合适的机器学习算法。

这里介绍的是数据集的划分。我们已经知道，仅仅具备一个很小的训练误差并不能保证我们的预测函数就是优秀的，因为这种“优秀”仅仅体现在了对于已知的训练样本的假设上，而无法保证见到新的样本时候还能做出足够好的预测，过拟合就是当中的典型例子。

为免假设函数陷于过拟合的情况，我们考虑将数据集划分为

+ 训练集（60%）

+ 交叉验证集（20%）

+ 测试集（20%）

或者有其他比例的数据集的划分，但上面这类比例的数据集划分比较典型

我们通过训练集确定模型，交叉验证集选择模型，测试集来评估模型的泛化能力。

> 注：并不建议只把数据集划分为训练集和测试集（虽然很多人是这么做的），这并不能很好的评估一个机器学习算法的泛化能力

### 机器学习诊断法之偏差与方差

通过分析出一个模型是处于高偏差还是高方差的情况，让我们能对症下药，采取不同的解决策略。

对于机器学习中的偏差和方差区别，请看这个视频：[机器学习中的偏差和方差](https://www.imooc.com/video/17609)

训练集上的代价函数和交叉验证集上的代价函数均很大的情况下，模型处于欠拟合（高偏差低偏差）；训练集上的代价函数很小和交叉验证集上的代价函数很大的情况下，模型处于过拟合（低偏差高方差）

### 机器学习诊断法之正则化和偏差、方差

对于机器学习算法中如何选定一个正则化参数，请看视频演示：https://www.bilibili.com/video/av50747658?p=62（3分30秒处）

下图反映了正则化过程中，训练集、交叉验证集误差随 *λ* 变化的曲线

![image-20200317171928440](.\image\image-20200317171928440.png)

### 机器学习诊断法之绘制学习曲线

学习曲线是学习算法的一个很好的合理检验。学习曲线是将训练集误差和交叉验证集误差作为训练集实例数量（𝑚）的函数绘制的图表。

通过绘制学习曲线，能让我们判断学习算法是否出现了高偏差或者高方差的问题。

 ![image-20200319224427041](.\image\image-20200319224427041.png)

如上图是模型高偏差情况下的学习曲线，此时增加再多的训练样本数量，其代价函数都不会有太大改观。此时，通过增加训练集样本来优化学习算法是徒劳的。

![image-20200319224957209](.\image\image-20200319224957209.png)

如上图是模型高方差情况下的学习曲线，此时增加更多训练集样本可能可以提高算法效果。 

### 决定下一步做什么

上面介绍了一系列的机器学习诊断法，机器学习诊断法能帮助我们判断模型是否存在高偏差或者高方差的问题，从而帮助我们判断哪些方法可能有助于改进学习算法的效果。那么这节来探讨我们该选择哪种方法来改进算法，而不至于采取徒劳的措施。

1、获得更多的训练实例——解决高方差 

2、尝试减少特征的数量——解决高方差 

3、尝试获得更多的特征——解决高偏差 

4、尝试增加多项式特征——解决高偏差 

5、尝试减少正则化参数 λ——解决高偏差 

6、尝试增加正则化参数λ——解决高方差 

那么我们又该选择怎样的一个神经网络结构呢？

+ 使用较小的神经网络，容易导致高偏差，但计算代
  价较小。

+ 使用较大的神经网络，容易导致高方差和过拟合，虽然计算
  代价比较大，但是可以通过正则化手段来调整而更加适应数据。 

通常选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。 

而对于神经网络中的隐藏层的层数的选择

+ 把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数（通常从一层开始逐渐增加层数）的神经网络训练神经网络， 然后选择交叉验证集代价最小的神经网络。

## 机器学习系统的设计

### 误差分析

构建一个学习算法的推荐方法为 

1、从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算
法。

2、绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择。

3、进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的实例，看看这些实例是否有某种系统化的趋势。

以我们的垃圾邮件过滤器为例，误差分析要做的既是检验交叉验证集中我们的算法产生错误预测的所有邮件，看：是否能将这些邮件按照类分组。例如医药品垃圾邮件，仿冒品垃圾邮件或者密码窃取邮件等。然后看分类器对哪一组邮件的预测误差最大，并着手优化。 
 然后思考怎样能改进分类器。例如，发现是否缺少某些特征，记下这些特征出现的次数。 

### 类偏斜的误差度量

类偏斜的情况表现为我们的训练集中有非常多的同一种类的实例，只有很少或没有其他类的实例，造成模型的预测总是偏向某一类。

例如我们希望用算法来预测癌症是否是恶性的，在我们的训练集中，只有 0.5%的实例
是恶性肿瘤。假设我们编写一个非学习而来的算法，在所有情况下都预测肿瘤是良性的，那么误差只有 0.5%。然而我们通过训练而得到的神经网络算法却有 1%的误差。这时，误差的大小是不能视为评判算法效果的依据的。

这种类偏斜的分类情况揭示了只用一个实数作为误差度量值评估分类模型的局限性，于是我们提出了查准率和查全率来评估一个分类模型。

![image-20200321155748970](.\image\image-20200321155748970.png)

+ 查准率（(Precision） = TP / (TP + FP)。例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。 

+ 查全率（或召回率，Recall） = TP / (TP+FN)。例，在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好

### 临界值

如果我们希望只在非常确信的情况下预测为真（eg：肿瘤为恶性），即我们希望更高的查准率，我们可以使用比 0.5 更大的临界值，如 0.7，0.9。这样做我们会减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。 
 如果我们希望提高查全率，尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地
检查、诊断，我们可以使用比 0.5 更小的临界值，如 0.3。 

### 查准率和查全率之间的权衡

一个模型评估值能让我们很快得出决策，选择其中表现最好的模型，而两个模型评估值会让我们犹豫，难以决策出哪一个是值得我们选择的模型，查准率和查全率则是让我们难以决策的两个评估值，我们不知道是该选择一个查准率相对查全率高的模型还是选择一个查全率相对查准率高的模型。于是在很多应用中，我们希望保证查准率和查全率之间的相对平衡。

于是人们把查准率和查全率综合起来，提出了 F1 值（F1 Score）。
![image-20200321170913272](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20200321170913272.png)

上一节谈了临界值的相关概念，那么我们该如何自动选定临界值？

一个合理的方法是我们可以试一试不同的临界值，并用这些不同的临界值在交叉验证集上检测哪一个临界值得到最高的F1值，就采用哪一个临界值。

### 机器学习数据

有一种机器学习中的普遍共识："取得成功的人不是拥有最好算法的人，而是拥有最多数据的人"。 
<u>那么这种说法在什么时候是真，什么时候是假呢？</u>因为如果我们有一个学习算法，并且如果这种说法是真的，那么得到大量的数据通常是保证我们具有一个高性能算法的最佳方式，而不是去争辩应该用什么样的算法。

一个关键的假设是：特征值有足够的信息量，且我们有一类很好的函数

## 支持向量机（SVM）

### 支持向量机的代价函数

支持向量机（SVM），在学习复杂的非线性方程（逻辑回归）时提供了一种更为清晰，更加强大的方式。

![image-20200323182506152](.\image\image-20200323182506152.png)

当你最优化上图中下面的代价函数，就得到了支持向量机学习得到的参数。

如图，支持向量机的假设函数预测出的不是概率，而是具体的类别。

![image-20200323182904636](.\image\image-20200323182904636.png)

### 大间距分类器

支持向量机有时又被称为大间隔分类器，这是因为支持向量机的假设函数会把正样本和负样本以最大的间距分开，这使得支持向量机具有鲁棒性：误分类的概率更小，或者说有更高的容错性。

![image-20200323212430399](.\image\image-20200323212430399.png)

但支持向量机算法会受到异常点的影响，如下图。

![image-20200323212631664](.\image\image-20200323212631664.png)

当正则化参数C设置得非常大的时候，决策边界从这条黑线变到这条粉线，而如果将 C 设置的不要太大，它可以忽略掉一些异常点的影响，则决策边界最终会得到这条黑线。

我们可以这么理解，回顾 𝐶 = 1/𝜆，因此： 
𝐶 较大时，相当于 𝜆 较小，可能会导致过拟合，高方差。 
𝐶 较小时，相当于 𝜆 较大，可能会导致欠拟合，高偏差。 

### 核函数1

我们之前讨论过可以使用高级数的多项式模型来解决无法用直线进行分隔的分类问题。

![image-20200323214423819](.\image\image-20200323214423819.png)

获得上图所示的判定边界，我们的模型可能是
$$
\theta_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_1x_2 + \theta_4x_1^2 + \theta_5x_2^2 + ...
$$


我们可以用一系列的新的特征 f 来替换模型中的每一项，例如令
$$
𝑓_1 = 𝑥_1,𝑓_2 = 𝑥_2,𝑓_3 =
𝑥_1𝑥_2,𝑓_4 = 𝑥_1^2,𝑓5 = 𝑥_2^2
$$
而得到
$$
ℎ𝜃(𝑥) = 𝜃_1𝑓_1 + 𝜃_2𝑓_2+...+𝜃_𝑛𝑓_𝑛
$$
然而，除了对原有的特征进行组合以外，有没有更好的方法来构造𝑓1,𝑓2,𝑓3？

我们可以利用核函数来计算出新的特征。 

给定一个训练实例𝑥 ，我们利用𝑥 的各个特征与我们预先选定的地标(landmarks)𝑙(1),𝑙(2),𝑙(3)的近似程度来选取新的特征𝑓1,𝑓2,𝑓3。

![image-20200323220617896](.\image\image-20200323220617896.png)

例如 

![image-20200323220212137](.\image\image-20200323220212137.png)

其中，![image-20200323220535571](.\image\image-20200323220535571.png)，为实例𝑥中所有特征与地标𝑙(1)之间的距离的和。

如果一个训练实例𝑥与地标𝐿之间的距离近似于 0，则新特征 𝑓近似于1，如果训练实例𝑥与地标𝐿之间距离较远，则𝑓近似于0。

这一关系可以被以下热力图反馈

![image-20200324181539872](.\image\image-20200324181539872.png)

### 核函数2

这里讲述的是如何选取标记点l(1)、l(2)、1(3)等。

假定我们有如下数据集
$$
(x^1,y^1),(x^2,y^2)，(x^3,y^3)⋯(x^m,y^m)
$$


我们就将每个样本作为一个标记点
$$
l^1=x^1，l^2=x^2，l^3=x^3⋯l^m=x^m
$$


则对于某个样本 ，我们计算其与各个标记点的距离
$$
f_1^i=sim(x^i,l^1)
$$

$$
f^i_2=sim(x^i,l^2)
$$

$$
⋮
$$

$$
f^i_m=sim(x_i,l_3)
$$

得到新的特征向量

![image-20200324182733425](.\image\image-20200324182733425.png)

则具备核函数的 SVM 的代价函数如下

![image-20200324182836775](.\image\image-20200324182836775.png)

这里需要注意的是，当参数θ过多时，为了计算方便，常常把
$$
\frac{1}{2}\sum_{j = 1}^{n}{θ_j^2}
$$


### SVM的使用建议

**使用库**

作为当今最为流行的分类算法之一，SVM 已经拥有了不少优秀的实现库，如 [libsvm](https://www.csie.ntu.edu.tw/~cjlin/libsvm/†) 等，因此，我们不再需要自己手动实现 SVM，而是调用别人已经实现的库。

在使用这些库时，你也需要做两件事

+ 选择参数C

+ 选择核函数

对于参数C的调节（ *C* 可以看做与正规化参数 *λ* 作用相反）

+ 低偏差**，**高方差，即遇到了过拟合时：减小C值。

+ 高偏差**，**低方差，即遇到了欠拟合时：增大 C值。

而对于核函数的选择

+ 当特征维度n较高，而样本规模m较小时，不宜使用核函数，否则容易引起过拟合。

+ 当特征维度 *n*较低，而样本规模 *m* 足够大时，考虑使用高斯核函数。不过在使用高斯核函数前，需要进行特征缩放（feature scaling）。另外，当核函数的参数 δ较大时，特征 f较为平缓（<u>见下图</u>），即各个样本的特征差异变小，此时会造成欠拟合（高偏差，低方差）；当 *δ* 较小时，特征 f 曲线变化剧烈（<u>见下下图</u>），即各个样本的特征差异变大，此时会造成过拟合（低偏差，高方差）

![image-20200324224446767](.\image\image-20200324224446767.png)

![image-20200324224506650](.\image\image-20200324224506650.png)

> 注：不是所有的相似度评估手段都能被用作SVM核函数，他们需要满足[ Mercer 理论](https://en.wikipedia.org/wiki/Mercer's_theorem)

### 分类模型的选择

目前，我们学到的分类模型有：（1）逻辑回归；（2）神经网络；（3）SVM。

怎么在这三者中做出选择呢？我们考虑特征维度 n 及样本规模 m

+ 如果 n相对于 m 非常大，例如 *n*=10000，而 *m*∈(10,1000)，此时选用逻辑回归或者无核的 SVM。

+ 如果 n较小，m适中，如 n∈(1,1000)，而 m∈(10,10000)，此时选用核函数为高斯核函数的 SVM。

+ 如果 n较小，m 较大，如 *n*∈(1,1000)，而 *m*>50000，此时，需要创建更多的特征（比如通过多项式扩展），再使用逻辑回归或者无核的 SVM。

神经网络对于上述情形都有不错的适应性，但是计算性能上较慢。

## 无监督学习

### 聚类

我们将物体被划分到不同集合的过程称之为<u>聚类（Clustering）</u>。

在聚类中，我们把物体所在的集合称之为<u>簇（cluster）</u>。

### K_Means算法

K-Means 这个算法是如何完成聚类过程的呢？其实算法名称中对此已有体现：

+ K: 描述了簇的数量，也就是应当聚合成的几何数。

+ Means：均值求解会是该算法的核心。

算法步骤

+ 根据设定的聚类数 K，随机地选择 K 个聚类中心（Cluster Centroid）

+ 评估各个样本到聚类中心的距离，如果样本距离第 *i* 个聚类中心更近，则认为其属于第 *i* 簇

![image-20200324232033539](.\image\image-20200324232033539.png)

+ 计算每个簇中样本的平均（Mean）位置，将聚类中心移动至该位置，像军队作战调整战略根据地以逐渐增强控制力和凝聚力。

+ 重复以上步骤直至各个聚类中心的位置不再发生改变。

> 注：某些聚类中心可能没有被分配到样本，这样的聚类中心就会被淘汰（意味着最终的类数可能会减少）或重新生成聚类中心。

### K_Means的代价函数

在引入 K-Means 的代价函数之前，先引入如下定义
$$
μ^i_c = 样本x^i被分配到的聚类中心
$$

$$
μ_k = 第k个簇的聚类中心
$$

$$
c^i = 第i个样本属于第几个簇。比如c^i = 5表示c^i属于第5个簇
$$

引入代价函数（也被称为失真代价函数）

![image-20200324233151898](.\image\image-20200324233151898.png)

样本分配时：我们固定住了 (μ1,μ2,...,μk)，而关于 (*c*(1),*c*(2),...,*c*(*m*)) 最小化了 J。

中心移动时：我们再关于 (μ1,μ2,...,μk)最小化了 *J*。

### 如何初始化聚类中心

K_Means算法最终会得到不同的算法，这取决于聚类中心的随机初始化状态不同。

为避免K_Means算法落在局部最优，可以对聚类中心尝试多次随机初始化。

![image-20200325230635115](.\image\image-20200325230635115.png)

> 在这 100 次迭代中，选择使得J最小的聚类中心作为最终的聚类中心。

而该方法计算量大，对K值较小的场景比较适用，能得到较好的结果。而对于K值较大的，则产生不了多大的影响

### 如何选取聚类数量

**肘部法则**

我们所需要做的是改变𝐾值（也就是聚类类别数目的总数），从而计算代价函数，绘制出K关于J的图形，像下图的“肘”图。

![image-20200325232149780](.\image\image-20200325232149780.png)

由图可见，在K = 3的时候达到一个肘点。在此之后，畸变值就下降的非常慢，看起来使用3个聚类是正确的。

但可能用于实际问题中是这么一种情况（见下图），K关于J的图像趋向于光滑，从而无法判断肘点在哪里，也就无法选取出合适的聚类数量。由此可见，不能指望肘部法则解决任何问题。

![image-20200325232528099](.\image\image-20200325232528099.png)

有一点需要注意的是：一般来说，K-Means 得到的聚类结果是服务于我们的后续目的（如通过聚类进行市场分析），所以不能脱离实际而单纯以数学方法来选择 *K* 值。

## 特征降维

### 降维概述

往往地，我们会期待有足够多的特征来促进学习模型的训练效果。但是高维的特征也有几个不好的地方

+ 学习性能下降，特征越多，学习算法的速度就越慢。

+ 过多的特征难于分辨，很难第一时间认识某个特征代表的意义。

+ 可能存在特征冗余，比如厘米和英尺就是一对冗余特征，他们本身代表的意义是一样的，并且能够相互转换，这就造成了特征冗余。

何谓降维，打个比方，如图，我们把图中二维平面上的每个点投射到一条直线上，那么原来的二维特征就降低为了一维特征

![image-20200329211342378](.\image\image-20200329211342378.png)

如图，我们把三维特征投影到二维平面，从而把三维特征降低到了二维

![image-20200329211918518](.\image\image-20200329211918518.png)

### PCA（主成分分析）

PCA，即主成分分析法，是特征降维的最常用手段。PCA 能从冗余特征中提取主要成分，在不太损失模型细节的情况下，提升了模型训练速度。

![image-20200329213238581](.\image\image-20200329213238581.png)

如上图所示，我们将<u>样本到红色向量的距离</u>称作是投影误差。以二维投影到一维为例，PCA 就是要找寻一条直线，使得各个特征的投影误差足够小，这样才能尽可能的保留原特征具有的信息。

假设我们要将特征从 n维度降到 *k* 维：PCA 首先找寻 k 个 n 维向量，然后将特征投影到这些向量构成的 k 维空间，并保证投影误差足够小。

![image-20200329213315151](.\image\image-20200329213315151.png)

### PCA算法流程

1、特征标准化

2、计算协方差矩阵 Σ

![image-20200329213955897](.\image\image-20200329213955897.png)

3、通过奇异值分解，求取 Σ 的特征向量

![image-20200329214649607](.\image\image-20200329214649607.png)

4、从 *U* 中取出前 k 个左奇异向量，构成一个约减矩阵 Ureduce

![image-20200329214808519](.\image\image-20200329214808519.png)

5、计算新的特征向量

![image-20200329214836405](.\image\image-20200329214836405.png)

### 特征还原

因为PCA仅保留了特征的主成分，所以PCA是一种有损的压缩方式。

假定我们获得的新特征向量为

![image-20200329214836405](.\image\image-20200329214836405.png)

那么，还原后的特征 xapprox 为

![image-20200329230053668](.\image\image-20200329230053668.png)

![image-20200329230108286](.\image\image-20200329230108286.png)

### 使用PCA的建议

不建议拿PCA来解决过拟合问题，正则化会是一个更好的选择。

PCA 不是必须的，在机器学习中，一定谨记不要提前优化，只有当算法运行效率不尽如如人意时，再考虑使用 PCA 或者其他特征降维手段来提升训练速度。

### PCA的用处

+ 加速学习算法的训练速度

+ 高维空间降维到低维空间，从而在低维空间可视化数据分析数据

例如下表中，我们有将近几十个特征来描述国家的经济水平，但是仔细观察发现，我们很难直观的看出各个国家的经济差异。

![image-20200329231548309](.\image\image-20200329231548309.png)

借助于 PCA，我们将特征降低到了二维，并在二维空间进行观察，很清楚的就能对比各个国家的经济水平，x轴表示国家总体GDP水平，y轴表示个人平均GDP水平。

![image-20200329231958472](.\image\image-20200329231958472.png)

## 异常检测

### 异常检测概述

异常检测（Anomaly Detection）是机器学习里面的一个常见应用，机器通过训练，将知道什么样的样本是正常样本，从而具备识别异常样本的能力。

飞机制造商在飞机引擎从生产线上流入市场前，会考虑进行异常检测，以防止不合格引擎造成恶劣结果。而为了进行异常检测，通常就需要采集一些引擎特征，如：
$$
x_1 = 引擎运转时的热量
$$

$$
x_2 = 引擎的振荡频率
$$



假定现在有引擎的数据集，这些数据都是正常样本，我们将其绘制到二维平面上

![image-20200330153708997](.\image\image-20200330153708997.png)

现在，新来了一个引擎样本（以绿色标志），它落到了正常样本中间，亦即，它表现了和正常样本类似的特征，所以，我们希望，新来的样本也会被当做是正常样本，从而让它顺利流入市场

![image-20200330161653043](.\image\image-20200330161653043.png)

与此同时，又来了一个引擎，由于他偏离正常样本汇集的位置过远，其理所当然被认为是异常样本，从而被回炉重造

![image-20200330161806992](.\image\image-20200330161806992.png)

综上所述，我们需要根据已有数据集构建一个概率模型 p(x)，如果某一样本被认为是正常样本的概率足够小，它就该被当做是异常

![image-20200330161908830](.\image\image-20200330161908830.png)

### 高斯分布

也称为正态分布

[高斯分布](https://www.bilibili.com/video/BV164411b7dx?p=89)

### 异常检测算法

在上节视频中我们已经认识到了高斯分布，那么接下来我们把它应用到异常检测算法

![image-20200330163434283](.\image\image-20200330163434283.png)

### 如何评估一个异常检测算法

<u>*数据集划分*</u>

训练集：有大量（或者完全）正常样本的无标签样本集。

在交叉验证集和测试集中包含了一些已知是异常的样本

举个栗子

假定我们的引擎数据集被标注了是否为异常样本和是否是正常样本，并且，含有正常样本 10000 个，异常样本 20 个。那么，我们可以这样划分数据集

+ 训练集含 6000个正常样本。

+ 交叉验证集含 2000个正常样本，10个异常样本。

+ 测试集含 2000个正常样本，10 个异常样本。

<u>*数据集的应用*</u>

训练集用于拟合模型p(x)，得出各类特征的参数均值*μ*和方差σ^2

交叉验证集用于选择不同的阈值*ε*，而评估模型在不同的阈值上的分类表现，从而选择阈值*ε*

测试集用于评估模型的分类表现（或者说是纠错表现），同时也由于异常样本非常少的，所以整个数据集是非常偏斜的，我们不能单纯的用预测准确率来评估算法优劣，可以考虑使用我们之前提过的评价手段

+ 查准率（Precision）与 召回率（Recall）

+ *F*1*score*

### 如何选择监督学习算法和异常检测算法

| 监督学习                                                     | 异常检测                                                     |
| :----------------------------------------------------------- | :----------------------------------------------------------- |
| 数据分布均匀                                                 | 数据非常偏斜，异常样本数目远小于正常样本数目                 |
| 可以根据对异常样本的拟合来知道异常样本的形态，从而预测新来的样本是否是异常样本 | 异常的类型不一，很难根据对现有的异常样本的拟合来判断出异常样本的形态 |
|                                                              |                                                              |

### 如何选择特征

<u>转换特征，使特征满足高斯分布</u>

假如我们一开始拿到的特征不满足高斯分布，那么我们可以通过对数操作或者其他操作将它转化为高斯分布。

<u>构建新特征</u>

找出分类出错的样本，观察其特征值，通过组合现有特征，来产生有助算法正确分类的特征。

举个栗子

例如，为了监测机房中的服务器异常状况，我们选定了如下特征
$$
x_1 = 内存使用率
$$

$$
x_2 = 每秒磁盘访问次数
$$

$$
x_3 = CPU负载
$$

$$
x_4 = 网络流量
$$

当异常发生时，这些值都会非常大。但是，我们遇到一个新的异常：程序执行时进入了某个死循环，此时 CPU负载 很高，而网络流量很低（业务全部卡死在服务器，而没有和客户端通信），要去识别这样一种情况，我们考虑创建新的特征
$$
x_5 = \frac{CPU负载}{网络流量}
$$


当上述异常发生时，该特征将会变得异常的大，有助于标识出异常发生。

### 多变量高斯分布

在原有的异常检测算法中，它存在一点瑕疵，即它不能自动捕捉两个特征之间的相关性，而事实上有些特征是存在相关的。这样导致的后果是一般的高斯分布模型尝试的是去同时抓住两个特征的偏差，因此创造出一个比较大的判定边界。如下图圆圆的洋红色的决策边界是一般高斯分布模型拟合出来的决策边界（一般高斯分布模型拟合出的决策边界都比较圆，不能拉伸、放缩到椭圆），但事实上，下图蓝色线上椭圆的决策边界才是更为真实的（多变量高斯分布模型拟合出来的）。

![image-20200330202835932](.\image\image-20200330202835932.png)

由此，引入了多变量高斯分布模型。

### 参数改变的影响

+ 改变 Σ 主对角线的数值可以进行不同方向的宽度拉伸。

+ 改变 Σ 次对角线的数值可以旋转分布图像。

+ 改变 *μ* 可以对分布图像进行位移。

具体改变参数的效果可以看看这个视频，[多变量高斯分布](https://www.bilibili.com/video/BV164411b7dx?p=94)，5分55秒开始

### 使用多变量高斯分布的异常检测算法

算法流程

1、选择一些足以反映异常样本的特征

2、对各个样本进行参数估计（注意此公式和一般高斯分布模型的公式存在差别）

![image-20200330205136119](.\image\image-20200330205136119.png)

3、当新的样本x到来时，计算p(x)（注意此公式和一般高斯分布模型的公式存在差别）

![image-20200330205249327](.\image\image-20200330205249327.png)

4、如果 p(x) < ϵ，则认为样本 *x* 是异常样本

### 一般高斯分布模型与多元高斯分布模型的差异

一般高斯分布模型是多元高斯分布模型的一个特殊的例子，即一般高斯分布模型是协方差矩阵 Σ除主对角线上元素之外的元素全为0的多元高斯分布模型。尽管如此，两个模型之间也存在一些差别。

| 一般高斯分布模型                                             | 多元高斯分布模型                                             |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 不能捕捉特征之间的相关性 但可以通过将特征进行组合的方法来解决 | 能自动捕捉特征之间的相关性，利用协方差矩阵 Σ 获得了各个特征相关性 |
| 计算代价低，能适应大规模的特征                               | 计算复杂                                                     |
| 在样本数目m较小时也工作良好                                  | 必须要有 𝑚 > 𝑛，不然的话协方差矩阵 不可逆的，通常需要 𝑚 > 10𝑛 另外特征冗余也会导致协方差矩阵不可逆，如不能存在x2 = 3x1或者x3 = x1+2x2 |
|                                                              |                                                              |

  一般来说，一般高斯分布模型比多元高斯分布模型应用更为广泛。

## 推荐系统

### 基于内容的推荐系统

假如我们有一份关于用户对电影的打分表（1 - 5分）？表示用户没有评价过家电。并假如该网站对于每部电影都给出了两个评价指数，构成了电影的二维特征向量 x，其中x1表示电影的浪漫指数，x2表示电影的动作指数。

| 电影 / 用户          | 小明 | 小红 | 小刚 | 小黄 | x1   | x2   |
| :------------------- | ---- | ---- | ---- | ---- | ---- | ---- |
| Love at last         | 5    | 5    | 0    | 0    | 0.9  | 0    |
| Romance for ever     | 5    | ?    | ?    | 0    | 1.0  | 0.01 |
| Cute puppies of love | ?    | 4    | 0    | ?    | 0.99 | 0    |
| Nonstop car chases   | 0    | 0    | 5    | 4    | 0.1  | 1.0  |
| Swords vs. karate    | 0    | 0    | 5    | ?    | 0    | 0.9  |

假设用户 *i* 对于每个指数的偏好程度由向量 *θ*(*i*) 所衡量，则我们估计该用户对电影 *j* 的打分为
$$
y(i,j)=(θ(i))^Tx^j
$$


但我们不知道*θ*(*i*)从何而来，用户并没有告诉我们他们对两种电影指标（浪漫、动作）的感兴趣程度，我们可以从每个用户点评过的电影评分和对应电影特征中找答案。

<u>算法流程如下</u>

<u>值得注意的是，基于内容的推荐系统算法和线性回归算法有很多相似之处</u>

另外，我们引入 *r*(*i*,*j*) 表示第 *i* 个用户是否对第 *j* 部电影进行了打分

![image-20200401234600942](.\image\image-20200401234600942.png)

联想我们学过的线性回归，我们可以把用户点评过的每部电影的特征作为特征，用户对该电影的评分作为标签构建数据集（以小明为例）。

需要说明的是，这里构建小明的电影评分数据集是为了辅助说明基于内容的推荐系统算法和线性回归算法的相似之处，事实上在基于内容的推荐系统算法的运算过程中并不存在诸如此类的数据集。

| 电影名字                                                     | 浪漫指数 | 动作指数 | 评分 |
| ------------------------------------------------------------ | -------- | -------- | ---- |
| Love at last                                                 | 0.9      | 0        | 5    |
| Romance for ever                                             | 1.0      | 0.01     | 5    |
| Nonstop car chases                                           | 0.1      | 1.0      | 0    |
| Swords vs. karate                                            | 0        | 0.9      | 0    |
| 这就把求出 *θ(小明)* 转为了一个线性回归中的最小化代价函数的问题（先随机初始化*θ(小明)*） |          |          |      |

![image-20200401233237163](.\image\image-20200401233237163.png)

而对于所有的用户1，2，.. n，我们就需要（可以看作下式是在上式的基础上加了一层求和项，下式是最终的代价函数）

![image-20200401233435535](.\image\image-20200401233435535.png)

有了代价函数，我们可以使用梯度下降算法迭代更新*θ(i)*

![image-20200401234151531](.\image\image-20200401234151531.png)

由此我们得出*θ*(*i*) ，便可以用于估计用户对没看过的电影的评分，从而决策该给用户推荐哪部他没看过的电影
$$
y(i,j)=(θ(i))^Tx^j
$$


### 协同过滤

上节说的基于内容的推荐算法和协同过滤可以看做是一个先有鸡还是先有蛋的问题。为什么这么说，且看下面。

上节说的的基于内容的推荐算法中，每部电影，我们都有评价其内容的特征向量 *x*。但是现实中，不会有任何网站，任何人有精力，有能力去评估每部电影的特征指数。因此，基于内容的推荐系统从构架初期，可能会遭遇非常大的阻力。

那假定我们先有了各个用户对电影特征指数（浪漫、动作）的偏爱评估 *θ*
$$
θ^1 = \left\{ \begin{matrix} 0 \\ 5 \\ 0 \end{matrix} \right\},θ^2 = \left\{ \begin{matrix} 0 \\ 5 \\ 0 \end{matrix} \right\},θ^3 = \left\{ \begin{matrix} 0 \\ 0 \\ 5 \end{matrix} \right\},θ^4 = \left\{ \begin{matrix} 0 \\ 0 \\ 5 \end{matrix} \right\}
$$


但是不知道每部电影的特征指数是多少

| 电影 / 用户          | 小明 | 小红 | 小刚 | 小黄 | x1   | x2   |
| :------------------- | ---- | ---- | ---- | ---- | ---- | ---- |
| Love at last         | 5    | 5    | 0    | 0    | ？   | ？   |
| Romance for ever     | 5    | ?    | ?    | 0    | ？   | ？   |
| Cute puppies of love | ?    | 4    | 0    | ?    | ？   | ？   |
| Nonstop car chases   | 0    | 0    | 5    | 4    | ？   | ？   |
| Swords vs. karate    | 0    | 0    | 5    | ?    | ？   | ？   |

联想我们学过的线性回归，我们可以把各用户的对电影特征指数的偏爱评估 *θ*作为特征，各用户对该电影的评分作为标签构建数据集（以电影Love at last为例）。

| 用户名                                                       | 对浪漫电影的偏爱 | 用户对动作电影的偏爱 | 评分 |
| ------------------------------------------------------------ | ---------------- | -------------------- | ---- |
| 小明                                                         | 5                | 0                    | 5    |
| 小红                                                         | 5                | 0                    | 5    |
| 小刚                                                         | 0                | 5                    | 0    |
| 小黄                                                         | 0                | 5                    | 0    |
| 这就把求出*x(Love at last)*转为了一个线性回归中的最小化代价函数的问题（先随机初始化*x(Love at last)*） |                  |                      |      |

![image-20200402003556164](.\image\image-20200402003556164.png)

那么现在我们可以基于*θ(1),...,θ(nu)* 来学习*x(i)*，对于所有的电影指数 *x*(1) ... *x*(*nm*)：

![image-20200402003616531](.\image\image-20200402003616531.png)

有了代价函数，我们可以使用梯度下降算法迭代更新*x(i)*

由此，我们得出*x(i)*，便可以用于估计电影的特征指数
$$
y(i,j)=(θ(i))^Tx^j
$$
需要注意的是，这里讲的协同过滤建立在每位用户都对数个电影进行了评价，并且每部电影都被数个用户评价过。

### 协同过滤算法

1、随机初始化 *x*(*i*),...,*x*(*nm*);*θ(1)*,...,*θ*(*nu*) 为一些较小值，与神经网络的参数初始化类似

2、用随机初始化的*θ*和*x*计算代价函数

![image-20200402100920096](.\image\image-20200402100920096.png)

3、使用梯度下降法来最小化 *J*(*x*(*i*),...,*x*(*nm*);*θ(1)*,...,*θ*(*nu*))

![image-20200402101036977](.\image\image-20200402101036977.png)

4、如果用户的偏好向量为 *θ*，而商品的特征向量为 *x*，则可以预测用户评价为 *θ^Tx*。

注意：因为协同过滤算法 *θ* 和 *x* 相互影响，因此，二者都没必要使用偏置 *θ*0 和 *x*0，即，*x*∈*Rn*、*θ*∈*Rn*。

### 获得类似电影的原理

当我们获得了电影 *i*

 的特征向量后，我们就可以通过计算 ||*x*(*j*)−*x*(*i*)|| 来比较电影 *j* 与电影 *i* 的相似度。那么，给予了电影 *j* 足够好评的用户，也会被推荐到类似的电影。

## 大规模机器学习

### 掌握大数据

在机器学习中，除了构建算法模型，为模型提供足够大，足够多的数据也成为了关键。同时，我们也需要做好准备，以更快速的方式处理、消化大数据。拥有了大数据，也就意味着在算法模型中，我们面临着一个很大的 *m* 值（样本数）。

### 随机梯度下降

针对于大数据集，我们引入了随机梯度下降算法。

该算法的执行过程

![image-20200403200201466](.\image\image-20200403200201466.png)

在大数据集中，随机梯度下降算法比梯度下降算法（也称批量梯度下降算法）性能更卓越。

### 随机梯度下降收敛

这节我们来探讨下如何确定随机梯度下降算法在收敛。

在梯度下降算法中我们通过绘制代价函数关于迭代次数的折线图来判断，在随机梯度下降算法中我们可以通过绘制损失函数关于迭代次数的折线图来判断。

当我们得到如下误差随迭代次数的变化曲线

![image-20200403205850467](.\image\image-20200403205850467.png)

说明算法是在收敛的。

当我们遇到如下误差随迭代次数的变化曲线

![image-20200403210157899](.\image\image-20200403210157899.png)

也不用担心，这并不意味着我们的学习率出了问题，有可能是我们的平均间隔取的太小，我们可以把绘制点设得大一点，那么曲线将更加平滑。

![image-20200403210351634](.\image\image-20200403210351634.png)

如果我们面临明显上升态势的曲线，那么就要考虑降低学习率 *α* 了。

![image-20200403213422201](.\image\image-20200403213422201.png)

并且学习率 *α*还可以随着迭代次数进行优化，实现学习率的动态变化，这样，随着迭代次数的增多，算法的下降步调就会放缓，避免出现抖动。

![image-20200403213529917](.\image\image-20200403213529917.png)

### Mini-Batch 梯度下降算法

Mini-Batch 梯度下降算法介于随机梯度下降算法和梯度下降算法之间。

其算法过程（假定设b = 10和m = 1000）

![image-20200403203429764](.\image\image-20200403203429764.png)

### 在线学习

用户登录了某提供货运服务的网站，输入了货运的发件地址和收件地址，该网站给出了货运报价，用户决定是购买该服务（*y*=1）或者是放弃购买该服务（*y*=0）。

特征向量 *x*包括了收发地址，报价信息，我们想要学习 *p*(*y*=1|*x*;*θ*) 来最优化报价。

![image-20200403214452656](.\image\image-20200403214452656.png)

在线学习与前面提到的一系列机器学习算法相比是它并不需要一个固定的样本集进行学习，而是不断接收样本，不断通过接收到的样本进行学习。因此，在线学习的前提是：我们拥有数据流源源不断地到达系统。

### MapReduce

可以把MapReduce理解成把一个计算任务分布到多个节点上进行并行计算，只要我们的计算任务可以用求和来表示。

我们可以使用多台机器进行 MapReduce，此时，Map任务被分配到多个机器完成

![image-20200403215455129](.\image\image-20200403215455129.png)

也可以使用单机多核心进行 MapReduce，此时，Map任务被分配到多个 CPU 核心完成

![image-20200403215524601](.\image\image-20200403215524601.png)

### 照片OCR

OCR又称光学字符识别，其工作流程为

1、文本检测：获得包含了文本的文本框。

2、字符分割：从文本框中分割出各个字符。

![image-20200403220451986](.\image\image-20200403220451986.png)

3、字符识别：字符分割中得到的只是一个个字符图形，在字符识别阶段，才能真正知道该字符类别。

![image-20200403220508523](.\image\image-20200403220508523.png)

### 滑动窗口分类器

这节看视频能更好地理解：[滑动窗口](https://www.bilibili.com/video/BV164411b7dx?p=109)

### 人工合成数据

人工合成数据有两个方式，举个栗子

+ 人工制造数据集：在字符识别阶段，为了更好的完成分类识别任务，我们就需要给系统提供尽可能多的训练图像，如果我们手头上拥有的图像不多，就需要人工合成更多的数据。例如，我们可以收集不同的字体，并为每种字体的每个字符加上随机背景，这样就可以人工扩展大量的字符图像。

+ 在原有数据集上动手获取新的数据集：也可以通过扭曲字符形状来合成新数据，这也会帮助机器更好地处理发生过形态变化的图像。

### 上限分析

以光学字符识别为例，光学字符识别并不是一个单一的过程，而是由若干过程构成的流水线。工程浩瀚，我们不可能在流水线的每一步都花费巨额的精力来作出改善，因此，我们需要一种手段来知道去改善哪一步是最值得的，上限分析（Ceiling analysis）就是手段之一。

![image-20200403223730821](.\image\image-20200403223730821.png)

所谓上限分析，就是我们假定某个组件及其前面组件的精度都达到了 100%，达到了上限，那么此时整个系统的精度能提升多少。

举个栗子，假定整个系统刚开始的精度是 72%（此时所有的组件都没达到100%的精度），我们令文本检测的精度是 100%（比如人工利用 PS 来定位图片中的文本框），此时，整个系统的精度能提升到 89%。即，如果我们付出足够多的精力来优化文本检测，那么理想情况下，能将系统的精度提升 17%。

|   组件   | 流水线精度 | 精度提升 |
| :------: | :--------: | -------- |
| 整个系统 |    72%     | --       |
| 文本检测 |    89%     | 17%      |
| 字符分割 |    90%     | 1%       |
| 字符识别 |    100%    | 10%      |

由上表可以看出，最值得花费精力的步骤是文本检测，最不值得花费精力的是字符分割。
